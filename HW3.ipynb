{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## HW3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import chainer\n",
    "from chainer import cuda, Function, gradient_check, report, training, utils, Variable\n",
    "from chainer import datasets, iterators, optimizers, serializers\n",
    "from chainer import Link, Chain, ChainList\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer.training import extensions\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import os\n",
    "from collections import Counter\n",
    "import math\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import csv\n",
    "import time\n",
    "import matplotlib.gridspec as gridspec\n",
    "import importlib\n",
    "%matplotlib inline\n",
    "%load_ext autoreload \n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open subtitles dataset configuration\n",
      "vocab size, en=13070, fr=36012\n",
      "hu_en_model_50000\\train_50000sen_3-3layers_100units_baseline_budoslab_SOFT_ATTN.log\n",
      "hu_en_model_50000\\seq2seq_50000sen_3-3layers_100units_baseline_budoslab_SOFT_ATTN.model\n",
      "here True\n",
      "not creating buckets as requested. will crash if buckets not present\n",
      "last saved epoch model=0\n",
      "loading model ...\n",
      "finished loading: hu_en_model_50000\\seq2seq_50000sen_3-3layers_100units_baseline_budoslab_SOFT_ATTN.model\n"
     ]
    }
   ],
   "source": [
    "#BASELINE DONT CHANGE \n",
    "%autoreload\n",
    "%run nmt_translate.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English predictions, s=46000, num=10:\n",
      "--------------------------------------------------\n",
      "sentence: 46000\n",
      "Src | - nem csak unalmas                                                              \n",
      "Ref | - no just dull                                                                  \n",
      "Hyp | - no _EOS                                                                       \n",
      "--------------------------------------------------\n",
      "precision | 1.0000\n",
      "recall | 0.5000\n",
      "--------------------------------------------------\n",
      "sentence: 46001\n",
      "Src | - Érdektelen                                                                    \n",
      "Ref | - insignificant                                                                 \n",
      "Hyp | - _UNK _UNK _EOS                                                                \n",
      "--------------------------------------------------\n",
      "precision | 0.3333\n",
      "recall | 0.5000\n",
      "--------------------------------------------------\n",
      "sentence: 46002\n",
      "Src | titkár                                                                          \n",
      "Ref | he s a secretary                                                                \n",
      "Hyp | yes secretary secretary _EOS                                                    \n",
      "--------------------------------------------------\n",
      "precision | 0.3333\n",
      "recall | 0.2500\n",
      "--------------------------------------------------\n",
      "sentence: 46003\n",
      "Src | mindig is tikár volt titkár is marad                                            \n",
      "Ref | he always was a secretary always will be                                        \n",
      "Hyp | i ve was the the the i did did very very _EOS                                   \n",
      "--------------------------------------------------\n",
      "precision | 0.0909\n",
      "recall | 0.1250\n",
      "--------------------------------------------------\n",
      "sentence: 46004\n",
      "Src | mulatságos                                                                      \n",
      "Ref | funny                                                                           \n",
      "Hyp | look is this _EOS                                                               \n",
      "--------------------------------------------------\n",
      "precision | 0.0000\n",
      "recall | 0.0000\n",
      "--------------------------------------------------\n",
      "sentence: 46005\n",
      "Src | amikor először láttam azt hittem orvos                                          \n",
      "Ref | the first time i saw him i thought he was a doctor                              \n",
      "Hyp | when when i i i i i him him _EOS                                                \n",
      "--------------------------------------------------\n",
      "precision | 0.3333\n",
      "recall | 0.2500\n",
      "--------------------------------------------------\n",
      "sentence: 46006\n",
      "Src | a mandulás                                                                      \n",
      "Ref | tonsils                                                                         \n",
      "Hyp | the tonsils _EOS                                                                \n",
      "--------------------------------------------------\n",
      "precision | 0.5000\n",
      "recall | 1.0000\n",
      "--------------------------------------------------\n",
      "sentence: 46007\n",
      "Src | egész biztosan a mandulás                                                       \n",
      "Ref | positively tonsils                                                              \n",
      "Hyp | i m be over _EOS                                                                \n",
      "--------------------------------------------------\n",
      "precision | 0.0000\n",
      "recall | 0.0000\n",
      "--------------------------------------------------\n",
      "sentence: 46008\n",
      "Src | sajnálom de nem alkalmas az idő monsieur giron                                  \n",
      "Ref | i m very sorry but this is not the time monsieur giron                          \n",
      "Hyp | but but but but but t t but the the the the _EOS                                \n",
      "--------------------------------------------------\n",
      "precision | 0.1667\n",
      "recall | 0.1667\n",
      "--------------------------------------------------\n",
      "sentence: 46009\n",
      "Src | - beszélnem kell Önnel                                                          \n",
      "Ref | - i ve got to see you                                                           \n",
      "Hyp | i must be to you _EOS                                                           \n",
      "--------------------------------------------------\n",
      "precision | 0.6000\n",
      "recall | 0.4286\n",
      "sentences matching filter = 10\n"
     ]
    }
   ],
   "source": [
    "_ = predict(s=46000, num=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 5000/5000 [07:48<00:00, 10.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 4.58\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=15.376652: 100%|██████████████████████| 5000/5000 [08:07<00:00, 10.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "dev perplexity | 90.104579\n",
      "# words in dev |  33576\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "bleu_score = compute_dev_bleu()\n",
    "print(\"{0:s}\".format(\"-\"*50))\n",
    "pplx = compute_dev_pplx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English predictions, s=45000, num=5000:\n",
      "sentences matching filter = 0\n",
      "--------------------------------------------------\n",
      "precision  | 0.2549\n",
      "recall     | 0.2616\n",
      "f1         | 0.2582\n"
     ]
    }
   ],
   "source": [
    "metrics = predict(s=NUM_TRAINING_SENTENCES, \n",
    "                         num=NUM_DEV_SENTENCES, display=False, plot=False)\n",
    "prec = np.sum(metrics[\"cp\"]) / np.sum(metrics[\"tp\"])\n",
    "rec = np.sum(metrics[\"cp\"]) / np.sum(metrics[\"t\"])\n",
    "f_score = 2 * (prec * rec) / (prec + rec)\n",
    "\n",
    "print(\"{0:s}\".format(\"-\"*50))\n",
    "print(\"{0:10s} | {1:0.4f}\".format(\"precision\", prec))\n",
    "print(\"{0:10s} | {1:0.4f}\".format(\"recall\", rec))\n",
    "print(\"{0:10s} | {1:0.4f}\".format(\"f1\", f_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# DONT RUN \n",
    "#_= predict(s=NUM_TRAINING_SENTENCES, num=NUM_DEV_SENTENCES, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English predictions, s=46009, num=1:\n",
      "--------------------------------------------------\n",
      "sentence: 46009\n",
      "Src | - beszélnem kell Önnel                                                          \n",
      "Ref | - i ve got to see you                                                           \n",
      "Hyp | i must be to you _EOS                                                           \n",
      "--------------------------------------------------\n",
      "precision | 0.6000\n",
      "recall | 0.4286\n",
      "sentences matching filter = 1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfgAAAGjCAYAAADAYQdLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJLWQCV6SpBYywUuS1EL/H1G3l8neyGUPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fdefc21710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_= predict(s=46009, num=1, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# changed to data2 folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "_WORD_SPLIT = re.compile(b\"([.,!?\\\"':~;)(])\")\n",
    "_DIGIT_RE = re.compile(br\"\\d\")\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "def basic_tokenizer(sentence):\n",
    "    \"\"\"Very basic tokenizer: split the sentence into a list of tokens.\"\"\"\n",
    "    words = []\n",
    "    for space_separated_fragment in sentence.strip().split():\n",
    "        words.extend(_WORD_SPLIT.sub(b\"\", w) for w in _WORD_SPLIT.split(space_separated_fragment))\n",
    "    return [w.lower() for w in words if w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create char words \n",
    "data_dir = os.path.join(\"C:\\\\Users\\\\user\\\\Desktop\\\\MT\\\\hw3\\\\hu_en_data2\")\n",
    "\n",
    "data_fname = {\"en\": os.path.join(data_dir, \"text_all.en\"),\n",
    "              \"fr\": os.path.join(data_dir, \"text_all.fr\")}\n",
    "\n",
    "fr_fname= \"C:/Users/user/Desktop/MT/hw3/hu_en_data2_50000/text.fr\"\n",
    "en_fname= \"C:/Users/user/Desktop/MT/hw3/hu_en_data2_50000/text.en\"\n",
    "\n",
    "num_lines = 0\n",
    "with open(data_fname[\"fr\"],\"rb\") as f_fr, open(data_fname[\"en\"],\"rb\") as f_en:\n",
    "        with open(fr_fname,\"wb\") as out_fr, open(en_fname,\"wb\") as out_en:\n",
    "            for i, (line_fr, line_en) in enumerate(zip(f_fr, f_en)):\n",
    "                if num_lines >= 50000:\n",
    "                    break\n",
    "                wf = line_fr.decode(\"utf-8\")\n",
    "                wf_ = \" \".join(wf)\n",
    "                we = line_en.decode(\"utf-8\")\n",
    "                we_ = \" \".join(we)\n",
    "                #words_fr = basic_tokenizer(wf_)\n",
    "                #words_en = basic_tokenizer(we_)\n",
    "                if len(words_fr) > 0 and len(words_en) > 0:\n",
    "                    # write to tokens file\n",
    "                    out_fr.write(wf_.encode(\"utf-8\"))\n",
    "                    out_en.write(we_.encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open subtitles dataset configuration\n",
      "Input folder not found\n",
      "Total lines=50046, valid lines=50000\n",
      "finished writing hu_en_data_CNN50000\\text.fr and hu_en_data_CNN50000\\text.en\n",
      "**************************************************\n",
      "en file\n",
      "**************************************************\n",
      "vocab length before: 13066\n",
      "vocab length after: 13066\n",
      "Finished generating vocabulary\n",
      "Vocab size=13070\n",
      "finished vocab processing for hu_en_data_CNN50000\\text.en\n",
      "**************************************************\n",
      "fr file\n",
      "**************************************************\n",
      "vocab length before: 36008\n",
      "vocab length after: 36008\n",
      "Finished generating vocabulary\n",
      "Vocab size=36012\n",
      "finished vocab processing for hu_en_data_CNN50000\\text.fr\n",
      "**************************************************\n",
      "finished creating input config for 50000 lines\n"
     ]
    }
   ],
   "source": [
    "%run prepare_seq2seq.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open subtitles dataset configuration\n",
      "vocab size, en=78, fr=77\n",
      "hu_en_model2_50000\\train_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN.log\n",
      "hu_en_model2_50000\\seq2seq_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN.model\n",
      "here False\n",
      "Splitting data into 7 buckets, each of width=3\n",
      "Saving bucket data\n",
      "Bucket 3, # items=297\n",
      "Bucket 6, # items=1950\n",
      "Bucket 9, # items=3173\n",
      "Bucket 12, # items=3652\n",
      "Bucket 15, # items=3766\n",
      "Bucket 18, # items=3812\n",
      "Bucket 21, # items=28350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=1, iter=62, loss=56.3203, mean loss=1.2316, bucket=7: 100%|███████████████| 45000/45000 [02:54<00:00, 212.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training on 45000 sentences\n",
      "--------------------------------------------------\n",
      "computing perplexity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=113.464272: 100%|███████████████████████████████████████████████████████████████| 500/500 [00:43<00:00, 10.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "dev perplexity | 23.610593\n",
      "# words in dev |  11827\n",
      "--------------------------------------------------\n",
      "Saving model\n",
      "Finished saving model\n",
      "hu_en_model2_50000\\train_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN.log\n",
      "hu_en_model2_50000\\dev_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN.log\n",
      "hu_en_model2_50000\\seq2seq_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN_1.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [00:35<00:00, 14.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 4.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=2, iter=45062, loss=55.6341, mean loss=1.2037, bucket=7: 100%|████████████| 45000/45000 [02:57<00:00, 207.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training on 45000 sentences\n",
      "--------------------------------------------------\n",
      "computing perplexity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=117.151131: 100%|███████████████████████████████████████████████████████████████| 500/500 [00:43<00:00, 10.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "dev perplexity | 25.873727\n",
      "# words in dev |  11827\n",
      "--------------------------------------------------\n",
      "Saving model\n",
      "Finished saving model\n",
      "hu_en_model2_50000\\train_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN.log\n",
      "hu_en_model2_50000\\dev_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN.log\n",
      "hu_en_model2_50000\\seq2seq_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN_2.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=3, iter=90062, loss=54.7161, mean loss=1.1874, bucket=7: 100%|████████████| 45000/45000 [02:58<00:00, 208.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training on 45000 sentences\n",
      "--------------------------------------------------\n",
      "computing perplexity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=117.320129: 100%|███████████████████████████████████████████████████████████████| 500/500 [00:43<00:00, 10.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "dev perplexity | 26.855140\n",
      "# words in dev |  11827\n",
      "--------------------------------------------------\n",
      "Saving model\n",
      "Finished saving model\n",
      "hu_en_model2_50000\\train_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN.log\n",
      "hu_en_model2_50000\\dev_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN.log\n",
      "hu_en_model2_50000\\seq2seq_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN_3.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [00:35<00:00, 13.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 6.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=4, iter=135062, loss=54.1539, mean loss=1.1753, bucket=7: 100%|███████████| 45000/45000 [02:56<00:00, 213.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training on 45000 sentences\n",
      "--------------------------------------------------\n",
      "computing perplexity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=118.409515: 100%|███████████████████████████████████████████████████████████████| 500/500 [00:42<00:00, 10.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "dev perplexity | 28.940900\n",
      "# words in dev |  11827\n",
      "--------------------------------------------------\n",
      "Saving model\n",
      "Finished saving model\n",
      "hu_en_model2_50000\\train_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN.log\n",
      "hu_en_model2_50000\\dev_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN.log\n",
      "hu_en_model2_50000\\seq2seq_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN_4.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=5, iter=180062, loss=53.7172, mean loss=1.1652, bucket=7: 100%|███████████| 45000/45000 [03:05<00:00, 208.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training on 45000 sentences\n",
      "--------------------------------------------------\n",
      "computing perplexity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=120.220146: 100%|███████████████████████████████████████████████████████████████| 500/500 [00:44<00:00, 10.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "dev perplexity | 29.388614\n",
      "# words in dev |  11827\n",
      "--------------------------------------------------\n",
      "Saving model\n",
      "Finished saving model\n",
      "hu_en_model2_50000\\train_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN.log\n",
      "hu_en_model2_50000\\dev_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN.log\n",
      "hu_en_model2_50000\\seq2seq_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN_5.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [00:36<00:00, 13.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 6.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=6, iter=225062, loss=53.5376, mean loss=1.1567, bucket=7: 100%|███████████| 45000/45000 [03:00<00:00, 213.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training on 45000 sentences\n",
      "--------------------------------------------------\n",
      "computing perplexity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=118.602219: 100%|███████████████████████████████████████████████████████████████| 500/500 [00:42<00:00, 10.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "dev perplexity | 27.416895\n",
      "# words in dev |  11827\n",
      "--------------------------------------------------\n",
      "Saving model\n",
      "Finished saving model\n",
      "hu_en_model2_50000\\train_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN.log\n",
      "hu_en_model2_50000\\dev_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN.log\n",
      "hu_en_model2_50000\\seq2seq_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN_6.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=7, iter=270062, loss=53.5882, mean loss=1.1494, bucket=7: 100%|███████████| 45000/45000 [02:58<00:00, 213.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training on 45000 sentences\n",
      "--------------------------------------------------\n",
      "computing perplexity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=118.716278: 100%|███████████████████████████████████████████████████████████████| 500/500 [00:42<00:00, 10.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "dev perplexity | 27.414554\n",
      "# words in dev |  11827\n",
      "--------------------------------------------------\n",
      "Saving model\n",
      "Finished saving model\n",
      "hu_en_model2_50000\\train_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN.log\n",
      "hu_en_model2_50000\\dev_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN.log\n",
      "hu_en_model2_50000\\seq2seq_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN_7.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [00:34<00:00, 14.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 8.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=8, iter=315062, loss=53.2666, mean loss=1.1421, bucket=7: 100%|███████████| 45000/45000 [02:59<00:00, 208.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training on 45000 sentences\n",
      "--------------------------------------------------\n",
      "computing perplexity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=118.489410: 100%|███████████████████████████████████████████████████████████████| 500/500 [00:42<00:00, 10.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "dev perplexity | 28.753577\n",
      "# words in dev |  11827\n",
      "--------------------------------------------------\n",
      "Saving model\n",
      "Finished saving model\n",
      "hu_en_model2_50000\\train_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN.log\n",
      "hu_en_model2_50000\\dev_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN.log\n",
      "hu_en_model2_50000\\seq2seq_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN_8.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=9, iter=360062, loss=53.2710, mean loss=1.1368, bucket=7: 100%|███████████| 45000/45000 [02:59<00:00, 208.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training on 45000 sentences\n",
      "--------------------------------------------------\n",
      "computing perplexity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=118.916077: 100%|███████████████████████████████████████████████████████████████| 500/500 [00:43<00:00, 10.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "dev perplexity | 27.978734\n",
      "# words in dev |  11827\n",
      "--------------------------------------------------\n",
      "Saving model\n",
      "Finished saving model\n",
      "hu_en_model2_50000\\train_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN.log\n",
      "hu_en_model2_50000\\dev_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN.log\n",
      "hu_en_model2_50000\\seq2seq_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN_9.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [00:33<00:00, 13.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 7.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=10, iter=405062, loss=52.9217, mean loss=1.1309, bucket=7: 100%|██████████| 45000/45000 [02:59<00:00, 216.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training on 45000 sentences\n",
      "--------------------------------------------------\n",
      "computing perplexity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=118.315414: 100%|███████████████████████████████████████████████████████████████| 500/500 [00:42<00:00, 10.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "dev perplexity | 28.328078\n",
      "# words in dev |  11827\n",
      "--------------------------------------------------\n",
      "Saving model\n",
      "Finished saving model\n",
      "hu_en_model2_50000\\train_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN.log\n",
      "hu_en_model2_50000\\dev_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN.log\n",
      "hu_en_model2_50000\\seq2seq_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN_10.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=11, iter=450062, loss=52.9395, mean loss=1.1256, bucket=7: 100%|██████████| 45000/45000 [03:00<00:00, 214.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training on 45000 sentences\n",
      "--------------------------------------------------\n",
      "computing perplexity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=133.234558: 100%|███████████████████████████████████████████████████████████████| 500/500 [00:42<00:00, 10.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "dev perplexity | 43.911839\n",
      "# words in dev |  11827\n",
      "--------------------------------------------------\n",
      "Saving model\n",
      "Finished saving model\n",
      "hu_en_model2_50000\\train_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN.log\n",
      "hu_en_model2_50000\\dev_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN.log\n",
      "hu_en_model2_50000\\seq2seq_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN_11.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [00:33<00:00, 14.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 7.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=12, iter=495062, loss=53.0710, mean loss=1.1190, bucket=7: 100%|██████████| 45000/45000 [02:58<00:00, 213.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training on 45000 sentences\n",
      "--------------------------------------------------\n",
      "computing perplexity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=124.077332: 100%|███████████████████████████████████████████████████████████████| 500/500 [00:42<00:00, 11.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "dev perplexity | 37.286204\n",
      "# words in dev |  11827\n",
      "--------------------------------------------------\n",
      "Saving model\n",
      "Finished saving model\n",
      "hu_en_model2_50000\\train_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN.log\n",
      "hu_en_model2_50000\\dev_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN.log\n",
      "hu_en_model2_50000\\seq2seq_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN_12.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=13, iter=540062, loss=52.9035, mean loss=1.1138, bucket=7: 100%|██████████| 45000/45000 [02:57<00:00, 210.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training on 45000 sentences\n",
      "--------------------------------------------------\n",
      "computing perplexity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=118.489609: 100%|███████████████████████████████████████████████████████████████| 500/500 [00:42<00:00, 11.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "dev perplexity | 35.608221\n",
      "# words in dev |  11827\n",
      "--------------------------------------------------\n",
      "Saving model\n",
      "Finished saving model\n",
      "hu_en_model2_50000\\train_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN.log\n",
      "hu_en_model2_50000\\dev_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN.log\n",
      "hu_en_model2_50000\\seq2seq_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN_13.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [00:32<00:00, 15.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 7.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=14, iter=585062, loss=52.6821, mean loss=1.1088, bucket=7: 100%|██████████| 45000/45000 [02:58<00:00, 214.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training on 45000 sentences\n",
      "--------------------------------------------------\n",
      "computing perplexity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=128.371094: 100%|███████████████████████████████████████████████████████████████| 500/500 [00:42<00:00, 10.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "dev perplexity | 37.732985\n",
      "# words in dev |  11827\n",
      "--------------------------------------------------\n",
      "Saving model\n",
      "Finished saving model\n",
      "hu_en_model2_50000\\train_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN.log\n",
      "hu_en_model2_50000\\dev_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN.log\n",
      "hu_en_model2_50000\\seq2seq_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN_14.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=15, iter=630062, loss=52.3333, mean loss=1.1039, bucket=7: 100%|██████████| 45000/45000 [02:57<00:00, 212.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training on 45000 sentences\n",
      "--------------------------------------------------\n",
      "computing perplexity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=129.650558: 100%|███████████████████████████████████████████████████████████████| 500/500 [00:42<00:00, 11.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "dev perplexity | 33.841613\n",
      "# words in dev |  11827\n",
      "--------------------------------------------------\n",
      "Saving model\n",
      "Finished saving model\n",
      "hu_en_model2_50000\\train_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN.log\n",
      "hu_en_model2_50000\\dev_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN.log\n",
      "hu_en_model2_50000\\seq2seq_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN_15.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [00:31<00:00, 15.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 8.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=16, iter=675062, loss=52.5808, mean loss=1.0987, bucket=7: 100%|██████████| 45000/45000 [02:58<00:00, 209.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training on 45000 sentences\n",
      "--------------------------------------------------\n",
      "computing perplexity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=129.816666: 100%|███████████████████████████████████████████████████████████████| 500/500 [00:42<00:00, 11.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "dev perplexity | 30.339557\n",
      "# words in dev |  11827\n",
      "--------------------------------------------------\n",
      "Saving model\n",
      "Finished saving model\n",
      "hu_en_model2_50000\\train_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN.log\n",
      "hu_en_model2_50000\\dev_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN.log\n",
      "hu_en_model2_50000\\seq2seq_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN_16.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=17, iter=720062, loss=52.5251, mean loss=1.0930, bucket=7: 100%|██████████| 45000/45000 [02:58<00:00, 200.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training on 45000 sentences\n",
      "--------------------------------------------------\n",
      "computing perplexity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=126.455353: 100%|███████████████████████████████████████████████████████████████| 500/500 [00:42<00:00, 11.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "dev perplexity | 27.570889\n",
      "# words in dev |  11827\n",
      "--------------------------------------------------\n",
      "Saving model\n",
      "Finished saving model\n",
      "hu_en_model2_50000\\train_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN.log\n",
      "hu_en_model2_50000\\dev_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN.log\n",
      "hu_en_model2_50000\\seq2seq_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN_17.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [00:31<00:00, 15.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 7.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=18, iter=765062, loss=52.6025, mean loss=1.0885, bucket=7: 100%|██████████| 45000/45000 [02:59<00:00, 203.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training on 45000 sentences\n",
      "--------------------------------------------------\n",
      "computing perplexity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=136.283112: 100%|███████████████████████████████████████████████████████████████| 500/500 [00:42<00:00, 10.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "dev perplexity | 29.052244\n",
      "# words in dev |  11827\n",
      "--------------------------------------------------\n",
      "Saving model\n",
      "Finished saving model\n",
      "hu_en_model2_50000\\train_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN.log\n",
      "hu_en_model2_50000\\dev_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN.log\n",
      "hu_en_model2_50000\\seq2seq_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN_18.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=19, iter=810062, loss=52.3196, mean loss=1.0841, bucket=7: 100%|██████████| 45000/45000 [02:58<00:00, 215.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training on 45000 sentences\n",
      "--------------------------------------------------\n",
      "computing perplexity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=135.793564: 100%|███████████████████████████████████████████████████████████████| 500/500 [00:42<00:00, 10.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "dev perplexity | 28.922788\n",
      "# words in dev |  11827\n",
      "--------------------------------------------------\n",
      "Saving model\n",
      "Finished saving model\n",
      "hu_en_model2_50000\\train_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN.log\n",
      "hu_en_model2_50000\\dev_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN.log\n",
      "hu_en_model2_50000\\seq2seq_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN_19.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [00:31<00:00, 15.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 8.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=20, iter=855062, loss=52.1302, mean loss=1.0795, bucket=7: 100%|██████████| 45000/45000 [02:58<00:00, 209.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training on 45000 sentences\n",
      "--------------------------------------------------\n",
      "computing perplexity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=136.850098: 100%|███████████████████████████████████████████████████████████████| 500/500 [00:42<00:00, 10.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "dev perplexity | 25.075407\n",
      "# words in dev |  11827\n",
      "--------------------------------------------------\n",
      "Saving model\n",
      "Finished saving model\n",
      "hu_en_model2_50000\\train_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN.log\n",
      "hu_en_model2_50000\\dev_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN.log\n",
      "hu_en_model2_50000\\seq2seq_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN_20.model\n",
      "Simple predictions (╯°□°）╯︵ ┻━┻\n",
      "training set predictions\n",
      "English predictions, s=0, num=2:\n",
      "--------------------------------------------------\n",
      "sentence: 0\n",
      "Src | Á l m o m b a n s e m h i t t e m v o l n a                                     \n",
      "Ref | i n e v e r d r e a m e d b e f o r e                                           \n",
      "Hyp | i u e r e e e t t n t t t t t t e e t t                                         \n",
      "--------------------------------------------------\n",
      "precision | 0.4500\n",
      "recall | 0.4737\n",
      "--------------------------------------------------\n",
      "sentence: 1\n",
      "Src | h o g y a z a j t ó k m e g n y í l n a k s o r b a e l ő t t e m e g y s z a b a d v i l á g f e l é\n",
      "Ref | i m g o n n a k n o c k t h e d o o r i n t o t h e w o r l d o f p e r f e c t f r e e\n",
      "Hyp | h o w t o o e e e e e e e e e e e e e e                                         \n",
      "--------------------------------------------------\n",
      "precision | 0.6000\n",
      "recall | 0.2727\n",
      "sentences matching filter = 2\n",
      "Simple predictions (╯°□°）╯︵ ┻━┻\n",
      "dev set predictions\n",
      "English predictions, s=45000, num=3:\n",
      "--------------------------------------------------\n",
      "sentence: 45000\n",
      "Src | - r e n d b e n                                                                 \n",
      "Ref | - a l l r i g h t                                                               \n",
      "Hyp | - a l l r i g h t g g _EOS                                                      \n",
      "--------------------------------------------------\n",
      "precision | 0.8182\n",
      "recall | 1.0000\n",
      "--------------------------------------------------\n",
      "sentence: 45001\n",
      "Src | c e s c a                                                                       \n",
      "Ref | c e s c a c e s c a                                                             \n",
      "Hyp | c e s c a s c a c a _EOS                                                        \n",
      "--------------------------------------------------\n",
      "precision | 0.9000\n",
      "recall | 0.9000\n",
      "--------------------------------------------------\n",
      "sentence: 45002\n",
      "Src | n e m l á t o k                                                                 \n",
      "Ref | i c a n t s e e                                                                 \n",
      "Hyp | i o e n t n t e e e e e _EOS                                                    \n",
      "--------------------------------------------------\n",
      "precision | 0.4167\n",
      "recall | 0.6250\n",
      "sentences matching filter = 3\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [00:31<00:00, 15.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 8.42\n",
      "--------------------------------------------------\n",
      "Final saving model\n",
      "Finished saving model\n",
      "hu_en_model2_50000\\train_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN.log\n",
      "hu_en_model2_50000\\dev_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN.log\n",
      "hu_en_model2_50000\\seq2seq_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [00:31<00:00, 16.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 8.42\n"
     ]
    }
   ],
   "source": [
    "#base 1-1,100,20 epochs\n",
    "%run nmt_translate.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open subtitles dataset configuration\n",
      "vocab size, en=78, fr=77\n",
      "hu_en_model2_50000\\train_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN.log\n",
      "hu_en_model2_50000\\seq2seq_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN.model\n",
      "here True\n",
      "not creating buckets as requested. will crash if buckets not present\n",
      "last saved epoch model=20\n",
      "loading model ...\n",
      "finished loading: hu_en_model2_50000\\seq2seq_50000sen_1-1layers_100units_test_budoslab_SOFT_ATTN.model\n"
     ]
    }
   ],
   "source": [
    "%run nmt_translate.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 5000/5000 [06:11<00:00, 12.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 6.63\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=47.874332: 100%|██████████████████████████████████████████████████████████████| 5000/5000 [08:27<00:00,  9.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "dev perplexity | 31.099950\n",
      "# words in dev | 128046\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "bleu_score = compute_dev_bleu()\n",
    "print(\"{0:s}\".format(\"-\"*50))\n",
    "pplx = compute_dev_pplx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English predictions, s=45000, num=5000:\n",
      "sentences matching filter = 0\n",
      "--------------------------------------------------\n",
      "precision  | 0.4409\n",
      "recall     | 0.2988\n",
      "f1         | 0.3562\n"
     ]
    }
   ],
   "source": [
    "metrics = predict(s=NUM_TRAINING_SENTENCES, \n",
    "                         num=NUM_DEV_SENTENCES, display=False, plot=False)\n",
    "prec = np.sum(metrics[\"cp\"]) / np.sum(metrics[\"tp\"])\n",
    "rec = np.sum(metrics[\"cp\"]) / np.sum(metrics[\"t\"])\n",
    "f_score = 2 * (prec * rec) / (prec + rec)\n",
    "\n",
    "print(\"{0:s}\".format(\"-\"*50))\n",
    "print(\"{0:10s} | {1:0.4f}\".format(\"precision\", prec))\n",
    "print(\"{0:10s} | {1:0.4f}\".format(\"recall\", rec))\n",
    "print(\"{0:10s} | {1:0.4f}\".format(\"f1\", f_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English predictions, s=5000, num=1:\n",
      "--------------------------------------------------\n",
      "sentence: 5000\n",
      "Src | a z u t ó b b i k é t é j s z a k a n e m a l u d t a m t ú l j ó l             \n",
      "Ref | i h a v e n t s l e p t v e r y w e l l y o u k n o w                           \n",
      "Hyp | t h e t e t t e e e e e e e e e e e e e                                         \n",
      "--------------------------------------------------\n",
      "precision | 0.3500\n",
      "recall | 0.2593\n",
      "sentences matching filter = 1\n"
     ]
    }
   ],
   "source": [
    "_= predict(s=NUM_DEV_SENTENCES, num=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open subtitles dataset configuration\n",
      "vocab size, en=78, fr=77\n",
      "hu_en_model2_50000\\train_50000sen_3-3layers_100units_test_budoslab_SOFT_ATTN.log\n",
      "hu_en_model2_50000\\seq2seq_50000sen_3-3layers_100units_test_budoslab_SOFT_ATTN.model\n",
      "here True\n",
      "not creating buckets as requested. will crash if buckets not present\n",
      "last saved epoch model=1\n",
      "loading model ...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (36012,100) into shape (77,100)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Niki\\Desktop\\MT\\hw3\\nmt_translate.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 681\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    682\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    683\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Niki\\Desktop\\MT\\hw3\\nmt_translate.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    661\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mload_existing_model\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"loading model ...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 663\u001b[1;33m             \u001b[0mserializers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_npz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_fil\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    664\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"finished loading: {0:s}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_fil\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Miniconda2\\envs\\mtenv\\lib\\site-packages\\chainer\\serializers\\npz.py\u001b[0m in \u001b[0;36mload_npz\u001b[1;34m(filename, obj)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNpzDeserializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m         \u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Miniconda2\\envs\\mtenv\\lib\\site-packages\\chainer\\serializer.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Miniconda2\\envs\\mtenv\\lib\\site-packages\\chainer\\link.py\u001b[0m in \u001b[0;36mserialize\u001b[1;34m(self, serializer)\u001b[0m\n\u001b[0;32m    689\u001b[0m         \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_children\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 691\u001b[1;33m             \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mserializer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    692\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    693\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Miniconda2\\envs\\mtenv\\lib\\site-packages\\chainer\\link.py\u001b[0m in \u001b[0;36mserialize\u001b[1;34m(self, serializer)\u001b[0m\n\u001b[0;32m    480\u001b[0m         \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_params\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m             \u001b[0mserializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m             \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mserializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Miniconda2\\envs\\mtenv\\lib\\site-packages\\chainer\\serializers\\npz.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    107\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m             \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopyto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (36012,100) into shape (77,100)"
     ]
    }
   ],
   "source": [
    "%run nmt_translate.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English predictions, s=5000, num=5000:\n",
      "--------------------------------------------------\n",
      "sentence: 5000\n",
      "Src | a z u t ó b b i k é t é j s z a k a n e m a l u d t a m t ú l j ó l             \n",
      "Ref | i h a v e n t s l e p t v e r y w e l l y o u k n o w                           \n",
      "Hyp | t h e t e t t e e e e e e e e e e e e e                                         \n",
      "--------------------------------------------------\n",
      "precision | 0.3500\n",
      "recall | 0.2593\n",
      "--------------------------------------------------\n",
      "sentence: 5001\n",
      "Src | Ó v a t o s n a k k e l l l e n n ü n k                                         \n",
      "Ref | s o i m j u s t - - y o u k n o w y o u r e a l w a y s l o o k i n g o v e r y o u r s h o u l d e r\n",
      "Hyp | o h e e e e e e o e o e e e e e e e e t                                         \n",
      "--------------------------------------------------\n",
      "precision | 0.4000\n",
      "recall | 0.1569\n",
      "--------------------------------------------------\n",
      "sentence: 5002\n",
      "Src | f o l y a m a t o s a t t ó l f é l s z h o g y v a n o t t v a l a m i m o s t m é g a z é g b o l t i s\n",
      "Ref | y o u a l w a y s t h i n k s o m e t h i n g s t h e r e a n d l i k e t h e w h o l e t h i n g w i t h t h e s k y n o w\n",
      "Hyp | i e u e e o e e e e e e e e e e e e e e                                         \n",
      "--------------------------------------------------\n",
      "precision | 0.5000\n",
      "recall | 0.1613\n",
      "--------------------------------------------------\n",
      "sentence: 5003\n",
      "Src | n e m t u d o m                                                                 \n",
      "Ref | i d o n t k n o w                                                               \n",
      "Hyp | i d o n t k n o w w w _EOS                                                      \n",
      "--------------------------------------------------\n",
      "precision | 0.8182\n",
      "recall | 1.0000\n",
      "--------------------------------------------------\n",
      "sentence: 5004\n",
      "Src | i t t k e l l l e n n i e v a l a h o l                                         \n",
      "Ref | w e l l h e s o b v i o u s l y a r o u n d h e r e s o m e w h e r e           \n",
      "Hyp | t e e e e e e e e e e e e e e e e e e e                                         \n",
      "--------------------------------------------------\n",
      "precision | 0.3500\n",
      "recall | 0.2000\n",
      "--------------------------------------------------\n",
      "sentence: 5005\n",
      "Src | f o l y t o n a z t m o n d o d h o g y i t t v a n e z v a g y a z             \n",
      "Ref | y e s y o u k e e p s a y i n g h e h e                                         \n",
      "Hyp | t e o l t y y y y e y e t t e e e e e e                                         \n",
      "--------------------------------------------------\n",
      "precision | 0.4500\n",
      "recall | 0.4500\n",
      "--------------------------------------------------\n",
      "sentence: 5006\n",
      "Src | n é z d m á r m i l y e n s ű r ű i t t a n ö v é n y z e t                     \n",
      "Ref | l o o k h o w t h i c k t h e b r u s h i s h e r e                             \n",
      "Hyp | l o o k h t t e e e e e e e e e e e e e                                         \n",
      "--------------------------------------------------\n",
      "precision | 0.5000\n",
      "recall | 0.3846\n",
      "--------------------------------------------------\n",
      "sentence: 5007\n",
      "Src | h a l e n n e i t t v a l a k i l á t n á n k                                   \n",
      "Ref | i f t h e r e s s o m e b o d y a r o u n d h e r e w e d s e e t h e m         \n",
      "Hyp | h e e e e e e e e e e e e e e e e e e e                                         \n",
      "--------------------------------------------------\n",
      "precision | 0.5000\n",
      "recall | 0.2778\n",
      "--------------------------------------------------\n",
      "sentence: 5008\n",
      "Src | m á s t h a l l u n k                                                           \n",
      "Ref | w e h e a r o t h e r t h i n g s                                               \n",
      "Hyp | w e l e e e e e e e e e e e _EOS                                                \n",
      "--------------------------------------------------\n",
      "precision | 0.2857\n",
      "recall | 0.2353\n",
      "--------------------------------------------------\n",
      "sentence: 5009\n",
      "Src | m o s t h i r t e l e n m i n t h a e l r e p ü l t v o l n a                   \n",
      "Ref | a l l o f a s u d d e n s o m e t h i n g g o e s f l y i n g                   \n",
      "Hyp | n o w i h e t t e e e e e e e e e e e e                                         \n",
      "--------------------------------------------------\n",
      "precision | 0.4000\n",
      "recall | 0.2581\n",
      "--------------------------------------------------\n",
      "sentence: 5010\n",
      "Src | s z e r i n t e m v a l a m i r ő l é s n e m v a l a k i r ő l k é n e b e s z é l n ü n k\n",
      "Ref | i t h i n k w e s h o u l d b e t a l k i n g m o r e i n t h e s e n s e o f w h a t\n",
      "Hyp | i e h i n k h e e e e e e e e e e e e e                                         \n",
      "--------------------------------------------------\n",
      "precision | 0.6000\n",
      "recall | 0.2791\n",
      "--------------------------------------------------\n",
      "sentence: 5011\n",
      "Src | - m e g n é z e m f e l f o r r t - e m á r a v í z                             \n",
      "Ref | i l l g o s e e i f t h e w a t e r s b o i l e d                               \n",
      "Hyp | - i l l l o o e e t t t t e e e e e e e                                         \n",
      "--------------------------------------------------\n",
      "precision | 0.6500\n",
      "recall | 0.5200\n",
      "--------------------------------------------------\n",
      "sentence: 5012\n",
      "Src | - k ö s z ö n ö m                                                               \n",
      "Ref | t h a n k y o u                                                                 \n",
      "Hyp | - t h a n k y o u u u _EOS                                                      \n",
      "--------------------------------------------------\n",
      "precision | 0.7273\n",
      "recall | 1.0000\n",
      "--------------------------------------------------\n",
      "sentence: 5013\n",
      "Src | n e m a k a r o k m e g h a l n i                                               \n",
      "Ref | i d o n t w a n t t o d i e                                                     \n",
      "Hyp | i d o n t w a n t t t t t t o o e e _EOS                                        \n",
      "--------------------------------------------------\n",
      "precision | 0.6667\n",
      "recall | 0.8571\n",
      "--------------------------------------------------\n",
      "sentence: 5014\n",
      "Src | n e m g o n d o l t a m h o g y e b b e n a m ű s o r b a n i l y e n m e g t ö r t é n h e t\n",
      "Ref | i d i d n t e v e r e x p e c t t h a t t h a t w o u l d b e a p o s s i b i l i t y o n t h i s s h o w a n d e v e r y d a y t h a t i m h e r e\n",
      "Hyp | i d i d t t t t t t t t e e e e e e e e                                         \n",
      "--------------------------------------------------\n",
      "precision | 1.0000\n",
      "recall | 0.2703\n",
      "--------------------------------------------------\n",
      "sentence: 5015\n",
      "Src | i d i ó t á n a k é r z e m m a g a m h o g y m é g m i n d i g i t t v a g y o k a k á r ú g y i s v é g e z h e t e m m i n t t o m m y\n",
      "Ref | i f e e l l i k e i m a n i d i o t f o r s t a y i n g t h a t i a m g o n n a e n d u p l i k e t o m m y\n",
      "Hyp | h o m e l l l l l e e e e e e e e e e e                                         \n",
      "--------------------------------------------------\n",
      "precision | 0.5500\n",
      "recall | 0.2037\n",
      "--------------------------------------------------\n",
      "sentence: 5016\n",
      "Src | a d u r v a b á n á s m ó d n e m e g y o l y a n d o l o g a m i t m o s t k e z e l n i t u d n é k\n",
      "Ref | i d o n t d e a l w e l l w i t h - - a b u s e i s n o t s o m e t h i n g t h a t i c a n h a n d l e r i g h t n o w\n",
      "Hyp | i e l e e e e e e e t t t t t t t t t t                                         \n",
      "--------------------------------------------------\n",
      "precision | 0.7000\n",
      "recall | 0.2333\n",
      "--------------------------------------------------\n",
      "sentence: 5017\n",
      "Src | f é l e k                                                                       \n",
      "Ref | i m s c a r e d                                                                 \n",
      "Hyp | i m a i r a r a f a _EOS                                                        \n",
      "--------------------------------------------------\n",
      "precision | 0.4000\n",
      "recall | 0.5000\n",
      "--------------------------------------------------\n",
      "sentence: 5018\n",
      "Src | j o h n n y m á r ö s s z e t ű z é s b e k e v e r e d e t t a c s o p o r t t a l a k a j a l o p á s m i a t t i s\n",
      "Ref | a n d j o h n n y w a s a l r e a d y o n t h e o u t s w i t h t h e g r o u p f o r s t e a l i n g f o o d\n",
      "Hyp | j o h n n e e e e e e e e e e e e e e a                                         \n",
      "--------------------------------------------------\n",
      "precision | 0.5000\n",
      "recall | 0.1818\n",
      "--------------------------------------------------\n",
      "sentence: 5019\n",
      "Src | h o g y t e h e t t e e z t v e l e                                             \n",
      "Ref | i j u s t - - h o w c o u l d h e d o t h a t t o h e r                         \n",
      "Hyp | h o w d o y o u t t t t t t t t t t t _EOS                                      \n",
      "--------------------------------------------------\n",
      "precision | 0.5789\n",
      "recall | 0.3929\n",
      "--------------------------------------------------\n",
      "sentence: 5020\n",
      "Src | n i n c s s e m m i é r t e l m e                                               \n",
      "Ref | i t d i d n t m a k e s e n s e                                                 \n",
      "Hyp | t h e r n n t n n n n e n e e n n n _EOS                                        \n",
      "--------------------------------------------------\n",
      "precision | 0.3889\n",
      "recall | 0.4375\n",
      "--------------------------------------------------\n",
      "sentence: 5021\n",
      "Src | e g y i l y e n k e d v e s h ö l g g y e l                                     \n",
      "Ref | s h e s s u c h a n i c e l a d y                                               \n",
      "Hyp | a n e t e a e e e e e e e e e e e e e e                                         \n",
      "--------------------------------------------------\n",
      "precision | 0.2500\n",
      "recall | 0.2941\n",
      "--------------------------------------------------\n",
      "sentence: 5022\n",
      "Src | j o h n n y                                                                     \n",
      "Ref | j o h n n y                                                                     \n",
      "Hyp | j o h n n y n y n y n _EOS                                                      \n",
      "--------------------------------------------------\n",
      "precision | 0.5455\n",
      "recall | 1.0000\n",
      "--------------------------------------------------\n",
      "sentence: 5023\n",
      "Src | m i t c s i n á l t á l                                                         \n",
      "Ref | h e y w h a t d i d y o u d o                                                   \n",
      "Hyp | w h a t a r e y o u d d d d _EOS                                                \n",
      "--------------------------------------------------\n",
      "precision | 0.7857\n",
      "recall | 0.7333\n",
      "--------------------------------------------------\n",
      "sentence: 5024\n",
      "Src | m i t t e t t é l c a r o l i n á v a l                                         \n",
      "Ref | - h u h - w h a t d i d y o u d o t o c a r o l i n a                           \n",
      "Hyp | w h a t d r e y o u d a a a a a a a a a                                         \n",
      "--------------------------------------------------\n",
      "precision | 0.6000\n",
      "recall | 0.4444\n",
      "--------------------------------------------------\n",
      "sentence: 5025\n",
      "Src | - f o g a l m a m s i n c s m i r ő l b e s z é l s z                           \n",
      "Ref | i d o n t k n o w w h a t y o u r e t a l k i n g a b o u t                     \n",
      "Hyp | - i o o n t t t t t t t t t t t e t e t                                         \n",
      "--------------------------------------------------\n",
      "precision | 0.4500\n",
      "recall | 0.3000\n",
      "--------------------------------------------------\n",
      "sentence: 5026\n",
      "Src | - m i a z h o g y f o g a l m a d s i n c s                                     \n",
      "Ref | w h a t d o y o u m e a n y o u d o n t k n o w w h a t i m t a l k i n g a b o u t\n",
      "Hyp | - w h a t a o y o u u o n n n n n n n t                                         \n",
      "--------------------------------------------------\n",
      "precision | 0.8000\n",
      "recall | 0.3810\n",
      "--------------------------------------------------\n",
      "sentence: 5027\n",
      "Src | m i t c s i n á l t á l v e l e                                                 \n",
      "Ref | - w h a t d y o u d o t o h e r - i d i d n t - -                               \n",
      "Hyp | w h a t a r e y o u d o o o o o o _EOS                                          \n",
      "--------------------------------------------------\n",
      "precision | 0.7059\n",
      "recall | 0.4800\n",
      "--------------------------------------------------\n",
      "sentence: 5028\n",
      "Src | v á g á s o k v a n n a k r a j t a m e g i l y e s m i                         \n",
      "Ref | s h e s a l l c u t u p a n d s h i t                                           \n",
      "Hyp | w e l l h e e e t t t t t t t t t t t t                                         \n",
      "--------------------------------------------------\n",
      "precision | 0.3000\n",
      "recall | 0.3158\n",
      "--------------------------------------------------\n",
      "sentence: 5029\n",
      "Src | - É n n e m t u d o m                                                           \n",
      "Ref | i d o n t - - i d o n t k n o w i                                               \n",
      "Hyp | i d o n t k n o w i o k w _EOS                                                  \n",
      "--------------------------------------------------\n",
      "precision | 0.8462\n",
      "recall | 0.6471\n",
      "--------------------------------------------------\n",
      "sentence: 5030\n",
      "Src | - m i v a n v e l e d                                                           \n",
      "Ref | w h a t s w r o n g w i t h y o u                                               \n",
      "Hyp | - w h a t a o u u t t t t y _EOS                                                \n",
      "--------------------------------------------------\n",
      "precision | 0.5714\n",
      "recall | 0.4706\n",
      "--------------------------------------------------\n",
      "sentence: 5031\n",
      "Src | n e m t u d o m                                                                 \n",
      "Ref | i d o n t k n o w i j u s t -                                                   \n",
      "Hyp | i d o n t k n o w w w _EOS                                                      \n",
      "--------------------------------------------------\n",
      "precision | 0.8182\n",
      "recall | 0.6000\n",
      "--------------------------------------------------\n",
      "sentence: 5032\n",
      "Src | c s a k e r r e j á r t a m é s                                                 \n",
      "Ref | - i k i n d o f c a m e t o i w a s w a l k i n g a r o u n d a n d             \n",
      "Hyp | i o l t t t t t t t t t t e e e e _EOS                                          \n",
      "--------------------------------------------------\n",
      "precision | 0.2941\n",
      "recall | 0.1471\n",
      "--------------------------------------------------\n",
      "sentence: 5033\n",
      "Src | - l á t t a m ő t                                                               \n",
      "Ref | i d o n t k n o w i w a s - - i s a w h e r                                     \n",
      "Hyp | - s a w s e e e e e e e _EOS                                                    \n",
      "--------------------------------------------------\n",
      "precision | 0.5000\n",
      "recall | 0.2727\n",
      "--------------------------------------------------\n",
      "sentence: 5034\n",
      "Src | - h o l l á t t a d                                                             \n",
      "Ref | y o u s a w h e r w h e r e                                                     \n",
      "Hyp | - w h y e o y o o o o o o y _EOS                                                \n",
      "--------------------------------------------------\n",
      "precision | 0.3571\n",
      "recall | 0.3571\n",
      "--------------------------------------------------\n",
      "sentence: 5035\n",
      "Src | e l k e l l m o n d a n o d m i t ö r t é n t                                   \n",
      "Ref | y o u g o t t o t e l l m e w h a t h a p p e n e d                             \n",
      "Hyp | y o u u l t t t t t e e e e e e e e e e                                         \n",
      "--------------------------------------------------\n",
      "precision | 0.6000\n",
      "recall | 0.4615\n",
      "--------------------------------------------------\n",
      "sentence: 5036\n",
      "Src | a z e r d ő b e n v o l t u n k t ö b b r e n e m e m l é k s z e m             \n",
      "Ref | w e w e r e i n t h e w o o d s a n d i d o n t r e a l l y - - i d o n t r e a l l y r e m e m b e r\n",
      "Hyp | i e e e e e e e e e e e e e e e e e e e                                         \n",
      "--------------------------------------------------\n",
      "precision | 0.5000\n",
      "recall | 0.1961\n",
      "--------------------------------------------------\n",
      "sentence: 5037\n",
      "Src | e l é m j ö t t d a n i e l é s a z z a l v á d o l t m e g h o g y b á n t o t t a m c a r o l i n á t\n",
      "Ref | i g e t a p p r o a c h e d b y d a n i e l a n d b a s i c a l l y s t a r t e d a c c u s i n g m e o f h u r t i n g c a r o l i n a\n",
      "Hyp | i h e t e e e e e e e e e e e e e e e e                                         \n",
      "--------------------------------------------------\n",
      "precision | 0.4000\n",
      "recall | 0.1176\n",
      "--------------------------------------------------\n",
      "sentence: 5038\n",
      "Src | - n e m t u d o m m i t m o n d h a t n é k                                     \n",
      "Ref | i d i d n t k n o w w h a t t o s a y                                           \n",
      "Hyp | - i d o n k k n o w w h w t t t t a a a                                         \n",
      "--------------------------------------------------\n",
      "precision | 0.7500\n",
      "recall | 0.7895\n",
      "--------------------------------------------------\n",
      "sentence: 5039\n",
      "Src | - m i t c s i n á l t á l v e l e                                               \n",
      "Ref | w h a t d i d y o u t o d o h e r                                               \n",
      "Hyp | - w h a t a r e y o u d o o o o o o _EOS                                        \n",
      "--------------------------------------------------\n",
      "precision | 0.6667\n",
      "recall | 0.7059\n",
      "--------------------------------------------------\n",
      "sentence: 5040\n",
      "Src | a z u t o l s ó d o l o g a m i r e e m l é k s z i k h o g y v e r e k e d e t t v e l e d ú g y h o g y n e m o n d d a z t n e k e m h o g y n e m é r t é l h o z z á\n",
      "Ref | t h e l a s t t h i n g s h e r e m e m b e r s i s g e t t i n g i n a f i g h t w i t h y o u s o y o u c a n t c o m e b a c k h e r e a n d t e l l m e t h a t y o u d i d n t t o u c h h e r\n",
      "Hyp | t h e t e e e e e e t e e t t e e t t e                                         \n",
      "--------------------------------------------------\n",
      "precision | 1.0000\n",
      "recall | 0.2041\n",
      "--------------------------------------------------\n",
      "sentence: 5041\n",
      "Src | - p e d i g é n n e m                                                           \n",
      "Ref | i d o n t                                                                       \n",
      "Hyp | - g e e e e e e i i i t t _EOS                                                  \n",
      "--------------------------------------------------\n",
      "precision | 0.1538\n",
      "recall | 0.4000\n",
      "--------------------------------------------------\n",
      "sentence: 5042\n",
      "Src | - a k k o r m i t ö r t é n t                                                   \n",
      "Ref | t h e n w h a t h a p p e n e d t o h e r                                       \n",
      "Hyp | - h h e h a t h p p e e e e e e _EOS                                            \n",
      "--------------------------------------------------\n",
      "precision | 0.7500\n",
      "recall | 0.5714\n",
      "--------------------------------------------------\n",
      "sentence: 5043\n",
      "Src | - f o g a l m a m s i n c s                                                     \n",
      "Ref | i d o n t k n o w                                                               \n",
      "Hyp | - i o o n t o o o o t o n n n n _EOS                                            \n",
      "--------------------------------------------------\n",
      "precision | 0.3750\n",
      "recall | 0.6667\n",
      "--------------------------------------------------\n",
      "sentence: 5044\n",
      "Src | - e z n e m a l e g j o b b v á l a s z e m b e r                               \n",
      "Ref | t h a t s n o t a v e r y g o o d a n s w e r r i g h t n o w m a n             \n",
      "Hyp | - t h t t t t t t t t t e e e n e n n n                                         \n",
      "--------------------------------------------------\n",
      "precision | 0.5500\n",
      "recall | 0.3235"
     ]
    }
   ],
   "source": [
    "# DONT RUN THIS\n",
    "_= predict(s=NUM_DEV_SENTENCES, num=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open subtitles dataset configuration\n",
      "vocab size, en=13070, fr=36012\n",
      "hu_en_model2_500\\train_500sen_1-1layers_100units_newtest_budoslab_SOFT_ATTN.log\n",
      "hu_en_model2_500\\seq2seq_500sen_1-1layers_100units_newtest_budoslab_SOFT_ATTN.model\n",
      "here False\n",
      "Splitting data into 1 buckets, each of width=3\n",
      "Saving bucket data\n",
      "Bucket 3, # items=450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=1, iter=1, loss=18.6120, mean loss=19.9530, bucket=1: 100%|████████████████████| 450/450 [02:04<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training on 450 sentences\n",
      "--------------------------------------------------\n",
      "computing perplexity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=35.157707: 100%|████████████████████████████████████████████████████████████████| 500/500 [00:13<00:00, 37.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "dev perplexity | 1131.120118\n",
      "# words in dev |   3007\n",
      "--------------------------------------------------\n",
      "Saving model\n",
      "Finished saving model\n",
      "hu_en_model2_500\\train_500sen_1-1layers_100units_newtest_budoslab_SOFT_ATTN.log\n",
      "hu_en_model2_500\\dev_500sen_1-1layers_100units_newtest_budoslab_SOFT_ATTN.log\n",
      "hu_en_model2_500\\seq2seq_500sen_1-1layers_100units_newtest_budoslab_SOFT_ATTN_1.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [00:07<00:00, 69.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 0.00\n",
      "Simple predictions (╯°□°）╯︵ ┻━┻\n",
      "training set predictions\n",
      "English predictions, s=0, num=2:\n",
      "--------------------------------------------------\n",
      "sentence: 0\n",
      "Src | Álmomban sem hittem volna                                                       \n",
      "Ref | i never dreamed before                                                          \n",
      "Hyp | i _EOS                                                                          \n",
      "--------------------------------------------------\n",
      "precision | 1.0000\n",
      "recall | 0.2500\n",
      "--------------------------------------------------\n",
      "sentence: 1\n",
      "Src | hogy az ajtók megnyílnak sorba előttem egy szabad világ felé                    \n",
      "Ref | i m gonna knock the door into the world of perfect free                         \n",
      "Hyp | i you t _EOS                                                                    \n",
      "--------------------------------------------------\n",
      "precision | 0.3333\n",
      "recall | 0.0833\n",
      "sentences matching filter = 2\n",
      "Simple predictions (╯°□°）╯︵ ┻━┻\n",
      "dev set predictions\n",
      "English predictions, s=450, num=3:\n",
      "--------------------------------------------------\n",
      "sentence: 450\n",
      "Src | - add ide                                                                       \n",
      "Ref | it s mine                                                                       \n",
      "Hyp | i you t _EOS                                                                    \n",
      "--------------------------------------------------\n",
      "precision | 0.0000\n",
      "recall | 0.0000\n",
      "--------------------------------------------------\n",
      "sentence: 451\n",
      "Src | azért van mert anyut baleset érte még nagyon régen                              \n",
      "Ref | it s because my mom had an accident along time ago                              \n",
      "Hyp | i you t _EOS                                                                    \n",
      "--------------------------------------------------\n",
      "precision | 0.0000\n",
      "recall | 0.0000\n",
      "--------------------------------------------------\n",
      "sentence: 452\n",
      "Src | egy templom előtt elütötte egy kamion és megsérült a feje hét éves korában      \n",
      "Ref | at age seven a grandpa told me that she got hit by a trunk infront of a church and hurt her head\n",
      "Hyp | i you t _EOS                                                                    \n",
      "--------------------------------------------------\n",
      "precision | 0.0000\n",
      "recall | 0.0000\n",
      "sentences matching filter = 3\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [00:07<00:00, 66.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 0.00\n",
      "--------------------------------------------------\n",
      "Final saving model\n",
      "Finished saving model\n",
      "hu_en_model2_500\\train_500sen_1-1layers_100units_newtest_budoslab_SOFT_ATTN.log\n",
      "hu_en_model2_500\\dev_500sen_1-1layers_100units_newtest_budoslab_SOFT_ATTN.log\n",
      "hu_en_model2_500\\seq2seq_500sen_1-1layers_100units_newtest_budoslab_SOFT_ATTN.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [00:07<00:00, 66.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 0.00\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "%run nmt_translate.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open subtitles dataset configuration\n",
      "vocab size, en=13070, fr=36012\n",
      "hu_en_model_50000\\train_50000sen_1-1layers_100units_newtest_budoslab_SOFT_ATTN.log\n",
      "hu_en_model_50000\\seq2seq_50000sen_1-1layers_100units_newtest_budoslab_SOFT_ATTN.model\n",
      "here False\n",
      "Splitting data into 1 buckets, each of width=10\n",
      "Saving bucket data\n",
      "Bucket 10, # items=45000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch=1, iter=100, loss=50.7820, mean loss=0.4373, bucket=1:  63%|█████████▍     | 28300/45000 [04:58<02:54, 95.49it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index -41416 is out of bounds for size 36012",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Niki\\Desktop\\MT\\hw3\\nmt_translate.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 681\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    682\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    683\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Niki\\Desktop\\MT\\hw3\\nmt_translate.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    674\u001b[0m                  \u001b[0mnum_buckets\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNUM_BUCKETS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m                  \u001b[0mnum_training\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNUM_TRAINING_SENTENCES\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m                  bucket_width=BUCKET_WIDTH, last_epoch_id=max_epoch_id)\n\u001b[0m\u001b[0;32m    677\u001b[0m         \u001b[0mcompute_dev_bleu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Niki\\Desktop\\MT\\hw3\\nmt_translate.py\u001b[0m in \u001b[0;36mbatch_train_loop\u001b[1;34m(bucket_fname, num_epochs, batch_size, num_buckets, num_training, bucket_width, log_mode, last_epoch_id)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m                     loss = model.encode_decode_train_batch(bucket_data[i:i+next_batch_end],\n\u001b[1;32m--> 401\u001b[1;33m                                                           buck_pad_lim, buck_pad_lim)\n\u001b[0m\u001b[0;32m    402\u001b[0m                     \u001b[0mtrain_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mcurr_len\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Niki\\Desktop\\MT\\hw3\\enc_dec_batch.py\u001b[0m in \u001b[0;36mencode_decode_train_batch\u001b[1;34m(self, batch_data, src_lim, tar_lim, train)\u001b[0m\n\u001b[0;32m    419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m         \u001b[1;31m# encode list of words/tokens\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfwd_encoder_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrev_encoder_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    422\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Niki\\Desktop\\MT\\hw3\\enc_dec_batch.py\u001b[0m in \u001b[0;36mencode_batch\u001b[1;34m(self, fwd_encoder_batch, rev_encoder_batch, train)\u001b[0m\n\u001b[0;32m    337\u001b[0m             \u001b[0mrev_w\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvar_rev_en\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 339\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm_enc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    340\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrev_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm_rev_enc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Niki\\Desktop\\MT\\hw3\\enc_dec_batch.py\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, word, lstm_layer_list, train)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlstm_layer_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_lstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed_enc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlstm_layer_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Niki\\Desktop\\MT\\hw3\\enc_dec_batch.py\u001b[0m in \u001b[0;36mfeed_lstm\u001b[1;34m(self, word, embed_layer, lstm_layer_list, train)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfeed_lstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membed_layer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlstm_layer_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;31m# get embedding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m         \u001b[0membed_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0membed_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m         \u001b[1;31m# feed into first LSTM layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[0mhs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlstm_layer_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membed_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Miniconda2\\envs\\mtenv\\lib\\site-packages\\chainer\\links\\connection\\embed_id.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \"\"\"\n\u001b[1;32m---> 50\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0membed_id\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mignore_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Miniconda2\\envs\\mtenv\\lib\\site-packages\\chainer\\functions\\connection\\embed_id.py\u001b[0m in \u001b[0;36membed_id\u001b[1;34m(x, W, ignore_label)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \"\"\"\n\u001b[1;32m--> 106\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mEmbedIDFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mignore_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mignore_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Miniconda2\\envs\\mtenv\\lib\\site-packages\\chainer\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *inputs)\u001b[0m\n\u001b[0;32m    197\u001b[0m         \u001b[1;31m# Forward prop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0min_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitervalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhooks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Miniconda2\\envs\\mtenv\\lib\\site-packages\\chainer\\functions\\connection\\embed_id.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     42\u001b[0m                 mask[..., None], 0, W.take(xp.where(mask, 0, x), axis=0)),\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index -41416 is out of bounds for size 36012"
     ]
    }
   ],
   "source": [
    "#testing cnn\n",
    "%run nmt_translate.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
